{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c51df2-ba21-4b2b-8763-5f7d6561a308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== í”„ë¡œê·¸ë¨ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\singa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ì´ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (epoch 8)\n",
      "===== í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 166307/386688 [3:00:11<4:13:23, 14.50it/s, acc=99.4, loss=0.175]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 9/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 264752/386688 [4:59:07<2:23:56, 14.12it/s, acc=99.4, loss=0.000131]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 9/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 308000/386688 [6:07:16<1:42:10, 12.84it/s, acc=99.4, loss=0.0265]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 9/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 362164/386688 [7:28:22<29:08, 14.02it/s, acc=99.4, loss=1.58e-5]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386688/386688 [7:57:31<00:00, 13.50it/s, acc=99.4, loss=4.05e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 ì™„ë£Œ - Loss: 6284.7327, Accuracy: 0.9941\n",
      "ğŸ’¾ ì—í­ 9 ëª¨ë¸ ì €ì¥ ì™„ë£Œ: resnet18_epoch9.pth\n",
      "ğŸ” ê²€ì¦ ì¤‘...\n",
      "ğŸ“Š Validation Accuracy: 0.7272\n",
      "ğŸŒŸ ìƒˆë¡œìš´ ìµœê³  ì •í™•ë„ ëª¨ë¸ ì €ì¥ë¨ (acc: 0.7272)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:   0%|                   | 830/386688 [00:49<5:58:49, 17.92it/s, acc=99.4, loss=6.97e-5]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=== í”„ë¡œê·¸ë¨ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ ===\")\n",
    "\n",
    "# 1. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, category in enumerate(['real', 'fake']):\n",
    "            category_path = os.path.join(root_dir, category)\n",
    "            for gender in ['ë‚¨ì„±', 'ì—¬ì„±']:\n",
    "                gender_path = os.path.join(category_path, gender)\n",
    "                if not os.path.exists(gender_path):\n",
    "                    continue\n",
    "                for filename in os.listdir(gender_path):\n",
    "                    if filename.lower().endswith(('.jpg', '.png')):\n",
    "                        full_path = os.path.join(gender_path, filename)\n",
    "                        self.image_paths.append(full_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        except Exception:\n",
    "            image = Image.new('RGB', (64, 64), (0, 0, 0))\n",
    "\n",
    "        image = self.to_tensor(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# 2. ë°ì´í„°ì…‹ ë° DataLoader ì„¤ì •\n",
    "train_dir = 'archive/frames/train'\n",
    "val_dir = 'archive/frames/validate'\n",
    "\n",
    "train_dataset = DeepfakeDataset(train_dir)\n",
    "val_dataset = DeepfakeDataset(val_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 3. ëª¨ë¸, ì¥ì¹˜, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. ì €ì¥ëœ ë§ˆì§€ë§‰ ì—í­ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "checkpoint_dir = '.'\n",
    "latest_epoch = 0\n",
    "\n",
    "for filename in os.listdir(checkpoint_dir):\n",
    "    match = re.match(r'resnet18_epoch(\\d+)\\.pth', filename)\n",
    "    if match:\n",
    "        epoch_num = int(match.group(1))\n",
    "        if epoch_num > latest_epoch:\n",
    "            latest_epoch = epoch_num\n",
    "\n",
    "if latest_epoch > 0:\n",
    "    checkpoint_path = f'resnet18_epoch{latest_epoch}.pth'\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"ğŸ”„ ì´ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (epoch {latest_epoch})\")\n",
    "else:\n",
    "    print(\"ğŸ†• ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤\")\n",
    "\n",
    "# ìµœê³  ì •í™•ë„ ì €ì¥ìš© ë³€ìˆ˜\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# 5. í•™ìŠµ ë£¨í”„\n",
    "num_epochs = 10\n",
    "print(\"===== í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ =====\")\n",
    "\n",
    "for epoch in range(latest_epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100)\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1} ì™„ë£Œ - Loss: {total_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    save_path = f'resnet18_epoch{epoch+1}.pth'\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"ğŸ’¾ ì—í­ {epoch+1} ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "\n",
    "    # ê²€ì¦\n",
    "    print(\"ğŸ” ê²€ì¦ ì¤‘...\")\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total if val_total > 0 else 0\n",
    "    print(f\"ğŸ“Š Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'resnet18_best.pth')\n",
    "        print(f\"ğŸŒŸ ìƒˆë¡œìš´ ìµœê³  ì •í™•ë„ ëª¨ë¸ ì €ì¥ë¨ (acc: {val_acc:.4f})\")\n",
    "\n",
    "print(\"âœ… ì „ì²´ í•™ìŠµ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0a3cd-056e-4921-a09a-80c7381e6db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
