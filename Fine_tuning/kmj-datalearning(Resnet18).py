import os
import re
from PIL import Image
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
import torch.optim as optim
from tqdm import tqdm

print("=== í”„ë¡œê·¸ë¨ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ ===")

# 1. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤
class DeepfakeDataset(Dataset):
    def __init__(self, root_dir):
        self.image_paths = []
        self.labels = []

        for label, category in enumerate(['real', 'fake']):
            category_path = os.path.join(root_dir, category)
            for gender in ['ë‚¨ì„±', 'ì—¬ì„±']:
                gender_path = os.path.join(category_path, gender)
                if not os.path.exists(gender_path):
                    continue
                for filename in os.listdir(gender_path):
                    if filename.lower().endswith(('.jpg', '.png')):
                        full_path = os.path.join(gender_path, filename)
                        self.image_paths.append(full_path)
                        self.labels.append(label)

        self.to_tensor = transforms.ToTensor()

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        try:
            image = Image.open(self.image_paths[idx]).convert('RGB')
        except Exception:
            image = Image.new('RGB', (64, 64), (0, 0, 0))

        image = self.to_tensor(image)
        label = self.labels[idx]
        return image, label

# 2. ë°ì´í„°ì…‹ ë° DataLoader ì„¤ì •
train_dir = 'archive/frames/train'
val_dir = 'archive/frames/validate'

train_dataset = DeepfakeDataset(train_dir)
val_dataset = DeepfakeDataset(val_dir)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)

# 3. ëª¨ë¸, ì¥ì¹˜, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.resnet18(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 4. ì €ì¥ëœ ë§ˆì§€ë§‰ ì—í­ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
checkpoint_dir = '.'
latest_epoch = 0

for filename in os.listdir(checkpoint_dir):
    match = re.match(r'resnet18_epoch(\d+)\.pth', filename)
    if match:
        epoch_num = int(match.group(1))
        if epoch_num > latest_epoch:
            latest_epoch = epoch_num

if latest_epoch > 0:
    checkpoint_path = f'resnet18_epoch{latest_epoch}.pth'
    model.load_state_dict(torch.load(checkpoint_path))
    print(f"ğŸ”„ ì´ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (epoch {latest_epoch})")
else:
    print("ğŸ†• ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤")

# ìµœê³  ì •í™•ë„ ì €ì¥ìš© ë³€ìˆ˜
best_val_acc = 0.0

# 5. í•™ìŠµ ë£¨í”„
num_epochs = 10
print("===== í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ =====")

for epoch in range(latest_epoch, num_epochs):
    model.train()
    total_loss = 0
    correct = 0
    total = 0

    loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", ncols=100)
    for images, labels in loop:
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

        loop.set_postfix(loss=loss.item(), acc=100 * correct / total)

    train_acc = correct / total
    print(f"Epoch {epoch+1} ì™„ë£Œ - Loss: {total_loss:.4f}, Accuracy: {train_acc:.4f}")

    # ëª¨ë¸ ì €ì¥
    save_path = f'resnet18_epoch{epoch+1}.pth'
    torch.save(model.state_dict(), save_path)
    print(f"ğŸ’¾ ì—í­ {epoch+1} ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")

    # ê²€ì¦
    print("ğŸ” ê²€ì¦ ì¤‘...")
    model.eval()
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            val_correct += (predicted == labels).sum().item()
            val_total += labels.size(0)

    val_acc = val_correct / val_total if val_total > 0 else 0
    print(f"ğŸ“Š Validation Accuracy: {val_acc:.4f}")

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), 'resnet18_best.pth')
        print(f"ğŸŒŸ ìƒˆë¡œìš´ ìµœê³  ì •í™•ë„ ëª¨ë¸ ì €ì¥ë¨ (acc: {val_acc:.4f})")

print("âœ… ì „ì²´ í•™ìŠµ ì™„ë£Œ")
