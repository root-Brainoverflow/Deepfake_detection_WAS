import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import f1_score
from tqdm import tqdm

from torchvision.datasets import ImageFolder

class CleanImageFolder(ImageFolder):
    def find_classes(self, directory):
        # ê¸°ì¡´ í´ë˜ìŠ¤ ì°¾ê¸°
        classes, class_to_idx = super().find_classes(directory)
        # ìˆ¨ê¹€ í´ë” ë“± ì œê±°
        classes = [c for c in classes if not c.startswith(".")]
        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        return classes, class_to_idx

def train():
    print("====== [0] PyTorch & í™˜ê²½ ì²´í¬ ======")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    BATCH_SIZE = 32
    NUM_EPOCHS = 10

    train_dir = "./frames/train"
    val_dir = "./frames/validate"

    print(f"train_dir: {train_dir} / val_dir: {val_dir}")
    print("train í´ë” fake í•˜ìœ„:", os.listdir(os.path.join(train_dir, "fake")) if os.path.exists(os.path.join(train_dir, "fake")) else "í´ë” ì—†ìŒ")
    print("train í´ë” real í•˜ìœ„:", os.listdir(os.path.join(train_dir, "real")) if os.path.exists(os.path.join(train_dir, "real")) else "í´ë” ì—†ìŒ")

    print("====== [1] ë°ì´í„° ì „ì²˜ë¦¬/ë¡œë“œ ======")
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.5]*3, [0.5]*3)
    ])

    for root, dirs, files in os.walk(train_dir):
        print(root, "â†’", len([f for f in files if f.endswith(('.jpg', '.png'))]), "images")

    train_dataset = datasets.ImageFolder(train_dir, transform=transform)
    val_dataset = datasets.ImageFolder(val_dir, transform=transform)

    print(f"âœ”ï¸ ì „ì²´ í•™ìŠµ ë°ì´í„° ìˆ˜: {len(train_dataset)}ê°œ")
    print(f"âœ”ï¸ ì „ì²´ ê²€ì¦ ë°ì´í„° ìˆ˜: {len(val_dataset)}ê°œ")
    print(f"âœ”ï¸ í´ë˜ìŠ¤ ëª©ë¡ (í´ë”ëª… ê¸°ì¤€): {train_dataset.classes}")

    if len(train_dataset) == 0 or len(val_dataset) == 0:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í´ë” ê²½ë¡œ/ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸!")
        return

    # ---- ì „ì²´ train ë°ì´í„°ì—ì„œ 20%ë§Œ ëœë¤ìœ¼ë¡œ ìƒ˜í”Œë§ ----
    use_len = int(len(train_dataset) * 0.2)
    ignore_len = len(train_dataset) - use_len
    subset_train, _ = random_split(train_dataset, [use_len, ignore_len])
    print(f"âœ”ï¸ ì‚¬ìš©í•  í•™ìŠµ ë°ì´í„° ìˆ˜(20%): {len(subset_train)}ê°œ")

    train_loader = DataLoader(subset_train, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)

    print("====== [2] í´ë˜ìŠ¤ ë¶ˆê· í˜• ê°€ì¤‘ì¹˜ ê³„ì‚° ======")
    # class_countsëŠ” ì „ì²´ ë°ì´í„° ê¸°ì¤€! (20% ë°ì´í„°ë¡œ ì¬ê³„ì‚° ì›í•˜ë©´ ì•„ë˜ ì£¼ì„ ì°¸ê³ )
    class_counts = torch.tensor([train_dataset.targets.count(i) for i in range(len(train_dataset.classes))], dtype=torch.float)
    print("í´ë˜ìŠ¤ë³„ ë°ì´í„° ìˆ˜:", dict(zip(train_dataset.classes, class_counts.tolist())))
    weights = 1. / class_counts
    print("ê°€ì¤‘ì¹˜(í´ë˜ìŠ¤ ë¶ˆê· í˜• ë°˜ì˜):", dict(zip(train_dataset.classes, weights.tolist())))
    weights = weights.to(device)
    criterion = nn.CrossEntropyLoss(weight=weights)

    print("====== [3] ëª¨ë¸ ë° Optimizer ì¤€ë¹„ ======")
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))  # í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ì¶¤
    model = model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    print(model)



    best_val_acc = 0.0
    for epoch in range(NUM_EPOCHS):
        print(f"\n\n=== [Epoch {epoch+1}/{NUM_EPOCHS}] í•™ìŠµ ì‹œì‘ ===")
        model.train()
        total_loss, correct, total = 0, 0, 0
        all_preds, all_labels = [], []

        train_bar = tqdm(train_loader, desc=f"[Train] Epoch {epoch+1}", ncols=80)
        for batch_idx, (imgs, labels) in enumerate(train_bar):
            imgs, labels = imgs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            batch_loss = loss.item() * imgs.size(0)
            total_loss += batch_loss
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += imgs.size(0)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            if (batch_idx+1) % 10 == 0 or (batch_idx+1) == len(train_loader):
                train_bar.set_postfix({
                    'Loss': f"{total_loss / total:.4f}",
                    'Acc': f"{correct / total:.4f}"
                })

        train_acc = correct / total
        train_f1 = f1_score(all_labels, all_preds, average='weighted')
        print(f"âœ… [Epoch {epoch+1}] Train Loss: {total_loss/total:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}")

        # ---- Validation ----
        print(f"\nğŸ” [Epoch {epoch+1}] ê²€ì¦ ë‹¨ê³„")
        model.eval()
        val_correct, val_total = 0, 0
        val_preds, val_labels = [], []

        with torch.no_grad():
            val_bar = tqdm(val_loader, desc=f"[Val] Epoch {epoch+1}", ncols=80)
            for batch_idx, (imgs, labels) in enumerate(val_bar):
                imgs, labels = imgs.to(device), labels.to(device)
                outputs = model(imgs)
                preds = torch.argmax(outputs, dim=1)
                val_correct += (preds == labels).sum().item()
                val_total += imgs.size(0)
                val_preds.extend(preds.cpu().numpy())
                val_labels.extend(labels.cpu().numpy())
                if (batch_idx+1) % 5 == 0 or (batch_idx+1) == len(val_loader):
                    val_bar.set_postfix({'Acc': f"{val_correct / val_total:.4f}"})

        val_acc = val_correct / val_total
        val_f1 = f1_score(val_labels, val_preds, average='weighted')
        print(f"ğŸ“Š [Epoch {epoch+1}] Val Acc: {val_acc:.4f}, F1: {val_f1:.4f}")

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), "best_model.pth")
            print(f"ğŸ’¾ [Epoch {epoch+1}] Best ëª¨ë¸ ì €ì¥! (Val Acc: {val_acc:.4f})")
        else:
            print(f"ğŸ“‰ [Epoch {epoch+1}] ëª¨ë¸ ì €ì¥ X (ì´ì „ ìµœê³  Val Acc: {best_val_acc:.4f})")

    print("\n====== ì „ì²´ í•™ìŠµ ì™„ë£Œ ======")
    print(f"ğŸ“Œ ìµœê³  ê²€ì¦ ì •í™•ë„(Best Val Acc): {best_val_acc:.4f}")

if __name__ == "__main__":
    train() 